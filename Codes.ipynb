{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940e9ec-3609-4d60-af71-56384be44e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Feature 1: VGG16\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG16 model pre-trained on ImageNet without top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model):\n",
    "    features = model.predict(generator, verbose=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model)\n",
    "test_features, test_labels = extract_features(test_generator, model)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_VGG16.csv')\n",
    "all_run_results_df.to_csv('all_run_results_VGG16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307057b-4d84-46e3-b8b1-f32d5139ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Feature 2: VGG19\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG19 model pre-trained on ImageNet without top layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model):\n",
    "    features = model.predict(generator, verbose=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model)\n",
    "test_features, test_labels = extract_features(test_generator, model)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_vgg19.csv')\n",
    "all_run_results_df.to_csv('all_run_results_vgg19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda2ba4-3355-4182-8f55-b8899007fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Feature 3: Resnet50\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load ResNet50 model pre-trained on ImageNet without top layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model):\n",
    "    features = model.predict(generator, verbose=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model)\n",
    "test_features, test_labels = extract_features(test_generator, model)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_resnet50.csv')\n",
    "all_run_results_df.to_csv('all_run_results_resnet50.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4538995-9a6e-4786-85c7-286bedf64680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Feature 4: GoogleNet (Inception v3)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load InceptionV3 model pre-trained on ImageNet without top layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model):\n",
    "    features = model.predict(generator, verbose=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model)\n",
    "test_features, test_labels = extract_features(test_generator, model)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_inceptionv3.csv')\n",
    "all_run_results_df.to_csv('all_run_results_inceptionv3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219f016-2cfc-4ac8-b41f-2c11d9c17c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HANDCRAFTED FEATURE: HOG\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define paths\n",
    "train_path = 'Enter your path to train folder'\n",
    "test_path = 'Enter your path to test folder'\n",
    "\n",
    "# Prepare data and labels\n",
    "def prepare_data(path, img_size=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                if file_path.endswith('.jpg') or file_path.endswith('.png'):\n",
    "                    img = imread(file_path, as_gray=True)\n",
    "                    img_resized = resize(img, img_size)\n",
    "                    data.append(img_resized)\n",
    "                    labels.append(folder)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Extract HOG features\n",
    "def extract_hog_features(data):\n",
    "    features = []\n",
    "    for image in data:\n",
    "        hog_features = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        features.append(hog_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Prepare training and testing data\n",
    "train_data, train_labels = prepare_data(train_path)\n",
    "test_data, test_labels = prepare_data(test_path)\n",
    "\n",
    "# Extract HOG features from the training and testing data\n",
    "train_features = extract_hog_features(train_data)\n",
    "test_features = extract_hog_features(test_data)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_hog.csv')\n",
    "all_run_results_df.to_csv('all_run_results_hog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32057de9-988d-4106-8a9c-ba5ef428ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HANDCRAFTED FEATURE: LBP\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define paths\n",
    "train_path = 'Enter your path to train folder'\n",
    "test_path = 'Enter your path to test folder'\n",
    "\n",
    "# Prepare data and labels\n",
    "def prepare_data(path, img_size=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                if file_path.endswith('.jpg') or file_path.endswith('.png'):\n",
    "                    img = imread(file_path, as_gray=True)\n",
    "                    img_resized = resize(img, img_size)\n",
    "                    data.append(img_resized)\n",
    "                    labels.append(folder)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Extract LBP features\n",
    "def extract_lbp_features(data, P=8, R=1):\n",
    "    features = []\n",
    "    for image in data:\n",
    "        lbp = local_binary_pattern(image, P=P, R=R, method='uniform')\n",
    "        (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, P + 3), range=(0, P + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)\n",
    "        features.append(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "# Prepare training and testing data\n",
    "train_data, train_labels = prepare_data(train_path)\n",
    "test_data, test_labels = prepare_data(test_path)\n",
    "\n",
    "# Extract LBP features from the training and testing data\n",
    "train_features = extract_lbp_features(train_data)\n",
    "test_features = extract_lbp_features(test_data)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_lbp.csv')\n",
    "all_run_results_df.to_csv('all_run_results_lbp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0d542-6795-44ce-a4a8-f1eb72cec06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HANDCRAFTED FEATURE: GLCM\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define paths\n",
    "train_path = 'Enter your path to train folder'\n",
    "test_path = 'Enter your path to test folder'\n",
    "\n",
    "# Prepare data and labels\n",
    "def prepare_data(path, img_size=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                if file_path.endswith('.jpg') or file_path.endswith('.png'):\n",
    "                    img = imread(file_path, as_gray=True)\n",
    "                    img_resized = resize(img, img_size)\n",
    "                    data.append(img_resized)\n",
    "                    labels.append(folder)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Extract GLCM features\n",
    "def extract_glcm_features(data, distances=[1], angles=[0], properties=['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']):\n",
    "    features = []\n",
    "    for image in data:\n",
    "        glcm = graycomatrix((image * 255).astype('uint8'), distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "        feature_vector = []\n",
    "        for prop in properties:\n",
    "            feature = graycoprops(glcm, prop)\n",
    "            feature_vector.append(feature.flatten())\n",
    "        features.append(np.hstack(feature_vector))\n",
    "    return np.array(features)\n",
    "\n",
    "# Prepare training and testing data\n",
    "train_data, train_labels = prepare_data(train_path)\n",
    "test_data, test_labels = prepare_data(test_path)\n",
    "\n",
    "# Extract GLCM features from the training and testing data\n",
    "train_features = extract_glcm_features(train_data)\n",
    "test_features = extract_glcm_features(test_data)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_glcm.csv')\n",
    "all_run_results_df.to_csv('all_run_results_glcm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1c19d-08d1-428e-89b2-ef85bf6bc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION MODEL 1: VGG16 & VGG19\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as preprocess_input_vgg16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as preprocess_input_vgg19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG16 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg16 = base_model_vgg16.output\n",
    "x_vgg16 = GlobalAveragePooling2D()(x_vgg16)\n",
    "model_vgg16 = Model(inputs=base_model_vgg16.input, outputs=x_vgg16)\n",
    "\n",
    "# Load VGG19 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg19 = base_model_vgg19.output\n",
    "x_vgg19 = GlobalAveragePooling2D()(x_vgg19)\n",
    "model_vgg19 = Model(inputs=base_model_vgg19.input, outputs=x_vgg19)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model_vgg16, model_vgg19):\n",
    "    features_vgg16 = model_vgg16.predict(generator, verbose=1)\n",
    "    features_vgg19 = model_vgg19.predict(generator, verbose=1)\n",
    "    features = np.concatenate([features_vgg16, features_vgg19], axis=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model_vgg16, model_vgg19)\n",
    "test_features, test_labels = extract_features(test_generator, model_vgg16, model_vgg19)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_vgg16_vgg19_fusion.csv')\n",
    "all_run_results_df.to_csv('all_run_results_vgg16_vgg19_fusion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10baa2-99bb-4dee-908c-7c133e5298d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION MODEL 2: VGG16 & Resnet50\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as preprocess_input_vgg16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as preprocess_input_resnet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG16 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg16 = base_model_vgg16.output\n",
    "x_vgg16 = GlobalAveragePooling2D()(x_vgg16)\n",
    "model_vgg16 = Model(inputs=base_model_vgg16.input, outputs=x_vgg16)\n",
    "\n",
    "# Load ResNet50 model pre-trained on ImageNet without top layers\n",
    "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_resnet50 = base_model_resnet50.output\n",
    "x_resnet50 = GlobalAveragePooling2D()(x_resnet50)\n",
    "model_resnet50 = Model(inputs=base_model_resnet50.input, outputs=x_resnet50)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model_vgg16, model_resnet50):\n",
    "    features_vgg16 = model_vgg16.predict(generator, verbose=1)\n",
    "    features_resnet50 = model_resnet50.predict(generator, verbose=1)\n",
    "    features = np.concatenate([features_vgg16, features_resnet50], axis=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model_vgg16, model_resnet50)\n",
    "test_features, test_labels = extract_features(test_generator, model_vgg16, model_resnet50)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_vgg16_resnet50_fusion.csv')\n",
    "all_run_results_df.to_csv('all_run_results_vgg16_resnet50_fusion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e69a7-af18-45bb-9ce2-9df126dfc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION MODEL 3: VGG16 & GoogleNet(Incetion v3)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as preprocess_input_vgg16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as preprocess_input_inception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG16 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg16 = base_model_vgg16.output\n",
    "x_vgg16 = GlobalAveragePooling2D()(x_vgg16)\n",
    "model_vgg16 = Model(inputs=base_model_vgg16.input, outputs=x_vgg16)\n",
    "\n",
    "# Load InceptionV3 (GoogLeNet) model pre-trained on ImageNet without top layers\n",
    "base_model_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_inception = base_model_inception.output\n",
    "x_inception = GlobalAveragePooling2D()(x_inception)\n",
    "model_inception = Model(inputs=base_model_inception.input, outputs=x_inception)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model_vgg16, model_inception):\n",
    "    features_vgg16 = model_vgg16.predict(generator, verbose=1)\n",
    "    features_inception = model_inception.predict(generator, verbose=1)\n",
    "    features = np.concatenate([features_vgg16, features_inception], axis=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model_vgg16, model_inception)\n",
    "test_features, test_labels = extract_features(test_generator, model_vgg16, model_inception)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_vgg16_inception_fusion.csv')\n",
    "all_run_results_df.to_csv('all_run_results_vgg16_inception_fusion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97951781-3943-47af-943f-a26b3583aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION MODEL 4: VGG19 & Resnet50\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as preprocess_input_vgg19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as preprocess_input_resnet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG19 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg19 = base_model_vgg19.output\n",
    "x_vgg19 = GlobalAveragePooling2D()(x_vgg19)\n",
    "model_vgg19 = Model(inputs=base_model_vgg19.input, outputs=x_vgg19)\n",
    "\n",
    "# Load ResNet50 model pre-trained on ImageNet without top layers\n",
    "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_resnet50 = base_model_resnet50.output\n",
    "x_resnet50 = GlobalAveragePooling2D()(x_resnet50)\n",
    "model_resnet50 = Model(inputs=base_model_resnet50.input, outputs=x_resnet50)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg19)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg19)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model_vgg19, model_resnet50):\n",
    "    features_vgg19 = model_vgg19.predict(generator, verbose=1)\n",
    "    features_resnet50 = model_resnet50.predict(generator, verbose=1)\n",
    "    features = np.concatenate([features_vgg19, features_resnet50], axis=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model_vgg19, model_resnet50)\n",
    "test_features, test_labels = extract_features(test_generator, model_vgg19, model_resnet50)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_vgg19_resnet50_fusion.csv')\n",
    "all_run_results_df.to_csv('all_run_results_vgg19_resnet50_fusion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a9c16-2856-4b08-a666-cf897b142e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION MODEL 5: VGG19 & GoogleNet (Inception v3)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as preprocess_input_vgg19\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as preprocess_input_inception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG19 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg19 = base_model_vgg19.output\n",
    "x_vgg19 = GlobalAveragePooling2D()(x_vgg19)\n",
    "model_vgg19 = Model(inputs=base_model_vgg19.input, outputs=x_vgg19)\n",
    "\n",
    "# Load InceptionV3 (GoogLeNet) model pre-trained on ImageNet without top layers\n",
    "base_model_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_inception = base_model_inception.output\n",
    "x_inception = GlobalAveragePooling2D()(x_inception)\n",
    "model_inception = Model(inputs=base_model_inception.input, outputs=x_inception)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg19)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg19)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model_vgg19, model_inception):\n",
    "    features_vgg19 = model_vgg19.predict(generator, verbose=1)\n",
    "    features_inception = model_inception.predict(generator, verbose=1)\n",
    "    features = np.concatenate([features_vgg19, features_inception], axis=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model_vgg19, model_inception)\n",
    "test_features, test_labels = extract_features(test_generator, model_vgg19, model_inception)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_vgg19_inception_fusion_10000.csv')\n",
    "all_run_results_df.to_csv('all_run_results_vgg19_inception_fusion_10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f153c61-ab27-4e49-9655-20abfe355e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION MODEL 6: Resnet50 & GoogleNet (Inception v3)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as preprocess_input_resnet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as preprocess_input_inception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load ResNet50 model pre-trained on ImageNet without top layers\n",
    "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_resnet50 = base_model_resnet50.output\n",
    "x_resnet50 = GlobalAveragePooling2D()(x_resnet50)\n",
    "model_resnet50 = Model(inputs=base_model_resnet50.input, outputs=x_resnet50)\n",
    "\n",
    "# Load InceptionV3 (GoogLeNet) model pre-trained on ImageNet without top layers\n",
    "base_model_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_inception = base_model_inception.output\n",
    "x_inception = GlobalAveragePooling2D()(x_inception)\n",
    "model_inception = Model(inputs=base_model_inception.input, outputs=x_inception)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_resnet50)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_resnet50)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Enter your path to train folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Enter your path to test folder',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model_resnet50, model_inception):\n",
    "    features_resnet50 = model_resnet50.predict(generator, verbose=1)\n",
    "    features_inception = model_inception.predict(generator, verbose=1)\n",
    "    features = np.concatenate([features_resnet50, features_inception], axis=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model_resnet50, model_inception)\n",
    "test_features, test_labels = extract_features(test_generator, model_resnet50, model_inception)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_resnet50_inception_fusion.csv')\n",
    "all_run_results_df.to_csv('all_run_results_resnet50_inception_fusion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eea221-b648-4afe-a145-03a1941477ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL PROPOSED MODEL : Fusion of VGG16 & VGG19 alongside handcrafted feature LBP\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as preprocess_input_vgg16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as preprocess_input_vgg19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load VGG16 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg16 = base_model_vgg16.output\n",
    "x_vgg16 = GlobalAveragePooling2D()(x_vgg16)\n",
    "model_vgg16 = Model(inputs=base_model_vgg16.input, outputs=x_vgg16)\n",
    "\n",
    "# Load VGG19 model pre-trained on ImageNet without top layers\n",
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x_vgg19 = base_model_vgg19.output\n",
    "x_vgg19 = GlobalAveragePooling2D()(x_vgg19)\n",
    "model_vgg19 = Model(inputs=base_model_vgg19.input, outputs=x_vgg19)\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg16)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C://Users//sunri//Downloads//Modified_Dataset//train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'C://Users//sunri//Downloads//Modified_Dataset//test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Extract LBP features\n",
    "def extract_lbp_features(image_paths):\n",
    "    lbp_features = []\n",
    "    for img_path in image_paths:\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n",
    "        hist, _ = np.histogram(lbp, bins=np.arange(0, 10), density=True)\n",
    "        lbp_features.append(hist)\n",
    "    return np.array(lbp_features)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(generator, model_vgg16, model_vgg19):\n",
    "    features_vgg16 = model_vgg16.predict(generator, verbose=1)\n",
    "    features_vgg19 = model_vgg19.predict(generator, verbose=1)\n",
    "    image_paths = [generator.filepaths[i] for i in range(generator.samples)]\n",
    "    features_lbp = extract_lbp_features(image_paths)\n",
    "    features = np.concatenate([features_vgg16, features_vgg19, features_lbp], axis=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, model_vgg16, model_vgg19)\n",
    "test_features, test_labels = extract_features(test_generator, model_vgg16, model_vgg19)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear', probability=True),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2, probability=True),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3, probability=True),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=0.1, probability=True),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=1, probability=True),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma='scale', C=10, probability=True),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Coarse KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Cosine KNN': KNeighborsClassifier(n_neighbors=5, metric='cosine'),\n",
    "    'Cubic KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {name: {'accuracy': [], 'auc': [], 'recall': [], 'precision': [], 'f1': []} for name in classifiers.keys()}\n",
    "all_run_results = []\n",
    "\n",
    "# Perform classification and record metrics\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    for run in tqdm(range(10)):\n",
    "        clf.fit(train_features, train_labels_enc)\n",
    "        pred_labels = clf.predict(test_features)\n",
    "        pred_probs = clf.predict_proba(test_features)[:, 1] if hasattr(clf, \"predict_proba\") else pred_labels\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_enc, pred_labels)\n",
    "        auc = roc_auc_score(test_labels_enc, pred_probs)\n",
    "        recall = recall_score(test_labels_enc, pred_labels)\n",
    "        precision = precision_score(test_labels_enc, pred_labels)\n",
    "        f1 = f1_score(test_labels_enc, pred_labels)\n",
    "\n",
    "        results[name]['accuracy'].append(accuracy)\n",
    "        results[name]['auc'].append(auc)\n",
    "        results[name]['recall'].append(recall)\n",
    "        results[name]['precision'].append(precision)\n",
    "        results[name]['f1'].append(f1)\n",
    "\n",
    "        all_run_results.append({\n",
    "            'classifier': name,\n",
    "            'run': run + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        })\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "summary = {}\n",
    "for name, metrics in results.items():\n",
    "    summary[name] = {metric: {'mean': np.mean(values), 'std': np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame({(clf, metric): vals for clf, metrics in summary.items() for metric, vals in metrics.items()})\n",
    "print(summary_df)\n",
    "\n",
    "# Convert all run results to DataFrame\n",
    "all_run_results_df = pd.DataFrame(all_run_results)\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('classification_summary_vgg16_vgg19_lbp_fusion.csv')\n",
    "all_run_results_df.to_csv('all_run_results_vgg16_vgg19_lbp_fusion.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
